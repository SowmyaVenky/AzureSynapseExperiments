{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(spark)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "* Next we are going to create an external table in the delta format referencing the location where we had created the external table in the Synapse serverless pool. This is an external table, so the table is not managed by spark and its corresponding warehouse. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "sparksql"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%sql\n",
        "CREATE TABLE temperatures_ext_delta ( \n",
        "    latitude float, \n",
        "    longitude float, \n",
        "    time string,\n",
        "\ttemperature_2m float\n",
        ") USING DELTA\n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures_delta/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "* Note that the external table was created inside the notebook. As soon as this executes, the folder we had referenced before in the Synapse serverless pool will get the _delta_log folder and it magically gets transformed into a delta table that we can read from inside the serverless pool!\n",
        "* Next we will start creating external tables for the paths we referenced before and merge the data back to the delta table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "sparksql"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%sql\n",
        "CREATE EXTERNAL TABLE temperatures_2018 \n",
        "USING PARQUET \n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures/AirQualityIndexWithTemperatures_5/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "sparksql"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "CREATE EXTERNAL TABLE temperatures_2019\n",
        "USING PARQUET \n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures/AirQualityIndexWithTemperatures_4/\";\n",
        "\n",
        "CREATE EXTERNAL TABLE temperatures_2020 \n",
        "USING PARQUET \n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures/AirQualityIndexWithTemperatures_3/\";\n",
        "\n",
        "CREATE EXTERNAL TABLE temperatures_2021 \n",
        "USING PARQUET \n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures/AirQualityIndexWithTemperatures_2/\";\n",
        "\n",
        "CREATE EXTERNAL TABLE temperatures_2022 \n",
        "USING PARQUET \n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures/AirQualityIndexWithTemperatures_1/\";\n",
        "\n",
        "CREATE EXTERNAL TABLE temperatures_2023\n",
        "USING PARQUET \n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures/AirQualityIndexWithTemperatures_0/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "* As we can see there are multiple lines output. Since all these are external table definitions, there is nothing much to show."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "sparksql"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%sql\n",
        "SHOW TABLES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "* As we can see all the tables we have defined are visible inside the spark layer. Let us merge all the tables to the main delta table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "sparksql"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%sql\n",
        "MERGE INTO temperatures_ext_delta AS TARGET\n",
        "USING temperatures_2018 AS SOURCE\n",
        "ON TARGET.latitude = SOURCE.latitude AND\n",
        "TARGET.longitude = SOURCE.longitude AND \n",
        "TARGET.`time` = SOURCE.`time` \n",
        "WHEN MATCHED THEN \n",
        "UPDATE SET \n",
        "    TARGET.temperature_2m = SOURCE.temperature_2m  \n",
        "WHEN NOT MATCHED THEN\n",
        "INSERT \n",
        "    ( TARGET.latitude, TARGET.longitude, TARGET.`time`, TARGET.temperature_2m )\n",
        "VALUES \n",
        "    ( SOURCE.latitude, SOURCE.longitude, SOURCE.`time`, SOURCE.temperature_2m );\n",
        "\n",
        "MERGE INTO temperatures_ext_delta AS TARGET\n",
        "USING temperatures_2019 AS SOURCE\n",
        "ON TARGET.latitude = SOURCE.latitude AND\n",
        "TARGET.longitude = SOURCE.longitude AND \n",
        "TARGET.`time` = SOURCE.`time` \n",
        "WHEN MATCHED THEN \n",
        "UPDATE SET \n",
        "    TARGET.temperature_2m = SOURCE.temperature_2m  \n",
        "WHEN NOT MATCHED THEN\n",
        "INSERT \n",
        "    ( TARGET.latitude, TARGET.longitude, TARGET.`time`, TARGET.temperature_2m )\n",
        "VALUES \n",
        "    ( SOURCE.latitude, SOURCE.longitude, SOURCE.`time`, SOURCE.temperature_2m );\n",
        "\n",
        "MERGE INTO temperatures_ext_delta AS TARGET\n",
        "USING temperatures_2020 AS SOURCE\n",
        "ON TARGET.latitude = SOURCE.latitude AND\n",
        "TARGET.longitude = SOURCE.longitude AND \n",
        "TARGET.`time` = SOURCE.`time` \n",
        "WHEN MATCHED THEN \n",
        "UPDATE SET \n",
        "    TARGET.temperature_2m = SOURCE.temperature_2m  \n",
        "WHEN NOT MATCHED THEN\n",
        "INSERT \n",
        "    ( TARGET.latitude, TARGET.longitude, TARGET.`time`, TARGET.temperature_2m )\n",
        "VALUES \n",
        "    ( SOURCE.latitude, SOURCE.longitude, SOURCE.`time`, SOURCE.temperature_2m );\n",
        "\n",
        "MERGE INTO temperatures_ext_delta AS TARGET\n",
        "USING temperatures_2021 AS SOURCE\n",
        "ON TARGET.latitude = SOURCE.latitude AND\n",
        "TARGET.longitude = SOURCE.longitude AND \n",
        "TARGET.`time` = SOURCE.`time` \n",
        "WHEN MATCHED THEN \n",
        "UPDATE SET \n",
        "    TARGET.temperature_2m = SOURCE.temperature_2m  \n",
        "WHEN NOT MATCHED THEN\n",
        "INSERT \n",
        "    ( TARGET.latitude, TARGET.longitude, TARGET.`time`, TARGET.temperature_2m )\n",
        "VALUES \n",
        "    ( SOURCE.latitude, SOURCE.longitude, SOURCE.`time`, SOURCE.temperature_2m );\n",
        "\n",
        "MERGE INTO temperatures_ext_delta AS TARGET\n",
        "USING temperatures_2022 AS SOURCE\n",
        "ON TARGET.latitude = SOURCE.latitude AND\n",
        "TARGET.longitude = SOURCE.longitude AND \n",
        "TARGET.`time` = SOURCE.`time` \n",
        "WHEN MATCHED THEN \n",
        "UPDATE SET \n",
        "    TARGET.temperature_2m = SOURCE.temperature_2m  \n",
        "WHEN NOT MATCHED THEN\n",
        "INSERT \n",
        "    ( TARGET.latitude, TARGET.longitude, TARGET.`time`, TARGET.temperature_2m )\n",
        "VALUES \n",
        "    ( SOURCE.latitude, SOURCE.longitude, SOURCE.`time`, SOURCE.temperature_2m );\n",
        "\n",
        "MERGE INTO temperatures_ext_delta AS TARGET\n",
        "USING temperatures_2023 AS SOURCE\n",
        "ON TARGET.latitude = SOURCE.latitude AND\n",
        "TARGET.longitude = SOURCE.longitude AND \n",
        "TARGET.`time` = SOURCE.`time` \n",
        "WHEN MATCHED THEN \n",
        "UPDATE SET \n",
        "    TARGET.temperature_2m = SOURCE.temperature_2m  \n",
        "WHEN NOT MATCHED THEN\n",
        "INSERT \n",
        "    ( TARGET.latitude, TARGET.longitude, TARGET.`time`, TARGET.temperature_2m )\n",
        "VALUES \n",
        "    ( SOURCE.latitude, SOURCE.longitude, SOURCE.`time`, SOURCE.temperature_2m );\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "* As we can see all the merges completed pretty quick and the data was merged into the delta table. We can query the data now to see the rows. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "sparksql"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%sql\n",
        "SELECT COUNT(*) FROM temperatures_ext_delta"
      ]
    }
  ],
  "metadata": {
    "description": "This will merge to an external data table.",
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
