{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "print(spark)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "venkyspark1001",
              "session_id": "1",
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-10-08T19:20:49.8772969Z",
              "session_start_time": "2023-10-08T19:20:49.9249897Z",
              "execution_start_time": "2023-10-08T19:22:18.1926678Z",
              "execution_finish_time": "2023-10-08T19:22:18.3540531Z",
              "spark_jobs": null,
              "parent_msg_id": "44181845-7272-42c7-8621-e7483ee734f0"
            },
            "text/plain": "StatementMeta(venkyspark1001, 1, 2, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pyspark.sql.session.SparkSession object at 0x7f8e3c843dc0>\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Next we are going to create an external table in the delta format referencing the location where we had created the external table in the Synapse serverless pool. This is an external table, so the table is not managed by spark and its corresponding warehouse. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "CREATE TABLE temperatures_ext_delta ( \r\n",
        "    latitude float, \r\n",
        "    longitude float, \r\n",
        "    time string,\r\n",
        "\ttemperature_2m float\r\n",
        ") USING DELTA\r\n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures_delta/\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "venkyspark1001",
              "session_id": "1",
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-10-08T19:28:35.439242Z",
              "session_start_time": null,
              "execution_start_time": "2023-10-08T19:28:35.5788715Z",
              "execution_finish_time": "2023-10-08T19:29:15.6929352Z",
              "spark_jobs": null,
              "parent_msg_id": "cf81649a-73da-46f4-b59f-92580f146b1d"
            },
            "text/plain": "StatementMeta(venkyspark1001, 1, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": []
              },
              "data": []
            },
            "text/plain": "<Spark SQL result set with 0 rows and 0 fields>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Note that the external table was created inside the notebook. As soon as this executes, the folder we had referenced before in the Synapse serverless pool will get the _delta_log folder and it magically gets transformed into a delta table that we can read from inside the serverless pool!\r\n",
        "* Next we will start creating external tables for the paths we referenced before and merge the data back to the delta table."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "CREATE EXTERNAL TABLE temperatures_2018 \r\n",
        "USING PARQUET \r\n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures/AirQualityIndexWithTemperatures_5/\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "venkyspark1001",
              "session_id": "1",
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-10-08T19:34:22.4359474Z",
              "session_start_time": null,
              "execution_start_time": "2023-10-08T19:34:22.5976662Z",
              "execution_finish_time": "2023-10-08T19:34:25.4634037Z",
              "spark_jobs": null,
              "parent_msg_id": "bcc5eba3-8a72-459c-838e-0dae453e391f"
            },
            "text/plain": "StatementMeta(venkyspark1001, 1, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": []
              },
              "data": []
            },
            "text/plain": "<Spark SQL result set with 0 rows and 0 fields>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "\r\n",
        "CREATE EXTERNAL TABLE temperatures_2019\r\n",
        "USING PARQUET \r\n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures/AirQualityIndexWithTemperatures_4/\";\r\n",
        "\r\n",
        "CREATE EXTERNAL TABLE temperatures_2020 \r\n",
        "USING PARQUET \r\n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures/AirQualityIndexWithTemperatures_3/\";\r\n",
        "\r\n",
        "CREATE EXTERNAL TABLE temperatures_2021 \r\n",
        "USING PARQUET \r\n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures/AirQualityIndexWithTemperatures_2/\";\r\n",
        "\r\n",
        "CREATE EXTERNAL TABLE temperatures_2022 \r\n",
        "USING PARQUET \r\n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures/AirQualityIndexWithTemperatures_1/\";\r\n",
        "\r\n",
        "CREATE EXTERNAL TABLE temperatures_2023\r\n",
        "USING PARQUET \r\n",
        "LOCATION \"abfss://datalake@venkydatalake1001.dfs.core.windows.net/temperatures/AirQualityIndexWithTemperatures_0/\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": "1",
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-10-08T19:36:35.0030779Z",
              "session_start_time": null,
              "execution_start_time": "2023-10-08T19:36:52.1242106Z",
              "execution_finish_time": "2023-10-08T19:36:52.1244343Z",
              "spark_jobs": null,
              "parent_msg_id": "e0c43f42-6572-4eb6-b2d0-2b3c69729b84"
            },
            "text/plain": "StatementMeta(, 1, -1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": []
              },
              "data": []
            },
            "text/plain": "<Spark SQL result set with 0 rows and 0 fields>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": []
              },
              "data": []
            },
            "text/plain": "<Spark SQL result set with 0 rows and 0 fields>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": []
              },
              "data": []
            },
            "text/plain": "<Spark SQL result set with 0 rows and 0 fields>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": []
              },
              "data": []
            },
            "text/plain": "<Spark SQL result set with 0 rows and 0 fields>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": []
              },
              "data": []
            },
            "text/plain": "<Spark SQL result set with 0 rows and 0 fields>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we can see there are multiple lines output. Since all these are external table definitions, there is nothing much to show."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "SHOW TABLES"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "venkyspark1001",
              "session_id": "1",
              "statement_id": 11,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-10-08T19:38:32.6652319Z",
              "session_start_time": null,
              "execution_start_time": "2023-10-08T19:38:32.808208Z",
              "execution_finish_time": "2023-10-08T19:38:33.9177592Z",
              "spark_jobs": null,
              "parent_msg_id": "da764900-5f9d-4d9a-a66b-19f376c38c44"
            },
            "text/plain": "StatementMeta(venkyspark1001, 1, 11, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": [
                  {
                    "name": "namespace",
                    "type": "string",
                    "nullable": false,
                    "metadata": {}
                  },
                  {
                    "name": "tableName",
                    "type": "string",
                    "nullable": false,
                    "metadata": {}
                  },
                  {
                    "name": "isTemporary",
                    "type": "boolean",
                    "nullable": false,
                    "metadata": {}
                  }
                ]
              },
              "data": [
                [
                  "default",
                  "temperatures_ext_delta",
                  false
                ],
                [
                  "default",
                  "temperatures_2018",
                  false
                ],
                [
                  "default",
                  "temperatures_2019",
                  false
                ],
                [
                  "default",
                  "temperatures_2020",
                  false
                ],
                [
                  "default",
                  "temperatures_2021",
                  false
                ],
                [
                  "default",
                  "temperatures_2022",
                  false
                ],
                [
                  "default",
                  "temperatures_2023",
                  false
                ]
              ]
            },
            "text/plain": "<Spark SQL result set with 7 rows and 3 fields>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we can see all the tables we have defined are visible inside the spark layer. Let us merge all the tables to the main delta table."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "MERGE INTO temperatures_ext_delta AS TARGET\r\n",
        "USING temperatures_2018 AS SOURCE\r\n",
        "ON TARGET.latitude = SOURCE.latitude AND\r\n",
        "TARGET.longitude = SOURCE.longitude AND \r\n",
        "TARGET.`time` = SOURCE.`time` \r\n",
        "WHEN MATCHED THEN \r\n",
        "UPDATE SET \r\n",
        "    TARGET.temperature_2m = SOURCE.temperature_2m  \r\n",
        "WHEN NOT MATCHED THEN\r\n",
        "INSERT \r\n",
        "    ( TARGET.latitude, TARGET.longitude, TARGET.`time`, TARGET.temperature_2m )\r\n",
        "VALUES \r\n",
        "    ( SOURCE.latitude, SOURCE.longitude, SOURCE.`time`, SOURCE.temperature_2m );\r\n",
        "\r\n",
        "MERGE INTO temperatures_ext_delta AS TARGET\r\n",
        "USING temperatures_2019 AS SOURCE\r\n",
        "ON TARGET.latitude = SOURCE.latitude AND\r\n",
        "TARGET.longitude = SOURCE.longitude AND \r\n",
        "TARGET.`time` = SOURCE.`time` \r\n",
        "WHEN MATCHED THEN \r\n",
        "UPDATE SET \r\n",
        "    TARGET.temperature_2m = SOURCE.temperature_2m  \r\n",
        "WHEN NOT MATCHED THEN\r\n",
        "INSERT \r\n",
        "    ( TARGET.latitude, TARGET.longitude, TARGET.`time`, TARGET.temperature_2m )\r\n",
        "VALUES \r\n",
        "    ( SOURCE.latitude, SOURCE.longitude, SOURCE.`time`, SOURCE.temperature_2m );\r\n",
        "\r\n",
        "MERGE INTO temperatures_ext_delta AS TARGET\r\n",
        "USING temperatures_2020 AS SOURCE\r\n",
        "ON TARGET.latitude = SOURCE.latitude AND\r\n",
        "TARGET.longitude = SOURCE.longitude AND \r\n",
        "TARGET.`time` = SOURCE.`time` \r\n",
        "WHEN MATCHED THEN \r\n",
        "UPDATE SET \r\n",
        "    TARGET.temperature_2m = SOURCE.temperature_2m  \r\n",
        "WHEN NOT MATCHED THEN\r\n",
        "INSERT \r\n",
        "    ( TARGET.latitude, TARGET.longitude, TARGET.`time`, TARGET.temperature_2m )\r\n",
        "VALUES \r\n",
        "    ( SOURCE.latitude, SOURCE.longitude, SOURCE.`time`, SOURCE.temperature_2m );\r\n",
        "\r\n",
        "MERGE INTO temperatures_ext_delta AS TARGET\r\n",
        "USING temperatures_2021 AS SOURCE\r\n",
        "ON TARGET.latitude = SOURCE.latitude AND\r\n",
        "TARGET.longitude = SOURCE.longitude AND \r\n",
        "TARGET.`time` = SOURCE.`time` \r\n",
        "WHEN MATCHED THEN \r\n",
        "UPDATE SET \r\n",
        "    TARGET.temperature_2m = SOURCE.temperature_2m  \r\n",
        "WHEN NOT MATCHED THEN\r\n",
        "INSERT \r\n",
        "    ( TARGET.latitude, TARGET.longitude, TARGET.`time`, TARGET.temperature_2m )\r\n",
        "VALUES \r\n",
        "    ( SOURCE.latitude, SOURCE.longitude, SOURCE.`time`, SOURCE.temperature_2m );\r\n",
        "\r\n",
        "MERGE INTO temperatures_ext_delta AS TARGET\r\n",
        "USING temperatures_2022 AS SOURCE\r\n",
        "ON TARGET.latitude = SOURCE.latitude AND\r\n",
        "TARGET.longitude = SOURCE.longitude AND \r\n",
        "TARGET.`time` = SOURCE.`time` \r\n",
        "WHEN MATCHED THEN \r\n",
        "UPDATE SET \r\n",
        "    TARGET.temperature_2m = SOURCE.temperature_2m  \r\n",
        "WHEN NOT MATCHED THEN\r\n",
        "INSERT \r\n",
        "    ( TARGET.latitude, TARGET.longitude, TARGET.`time`, TARGET.temperature_2m )\r\n",
        "VALUES \r\n",
        "    ( SOURCE.latitude, SOURCE.longitude, SOURCE.`time`, SOURCE.temperature_2m );\r\n",
        "\r\n",
        "MERGE INTO temperatures_ext_delta AS TARGET\r\n",
        "USING temperatures_2023 AS SOURCE\r\n",
        "ON TARGET.latitude = SOURCE.latitude AND\r\n",
        "TARGET.longitude = SOURCE.longitude AND \r\n",
        "TARGET.`time` = SOURCE.`time` \r\n",
        "WHEN MATCHED THEN \r\n",
        "UPDATE SET \r\n",
        "    TARGET.temperature_2m = SOURCE.temperature_2m  \r\n",
        "WHEN NOT MATCHED THEN\r\n",
        "INSERT \r\n",
        "    ( TARGET.latitude, TARGET.longitude, TARGET.`time`, TARGET.temperature_2m )\r\n",
        "VALUES \r\n",
        "    ( SOURCE.latitude, SOURCE.longitude, SOURCE.`time`, SOURCE.temperature_2m );\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": "1",
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-10-08T19:42:07.6865978Z",
              "session_start_time": null,
              "execution_start_time": "2023-10-08T19:43:23.9800107Z",
              "execution_finish_time": "2023-10-08T19:43:23.980243Z",
              "spark_jobs": null,
              "parent_msg_id": "79fabe8b-e13a-4c4a-9688-97db7af0323d"
            },
            "text/plain": "StatementMeta(, 1, -1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": [
                  {
                    "name": "num_affected_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_updated_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_deleted_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_inserted_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  }
                ]
              },
              "data": [
                [
                  "876000",
                  "0",
                  "0",
                  "876000"
                ]
              ]
            },
            "text/plain": "<Spark SQL result set with 1 rows and 4 fields>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": [
                  {
                    "name": "num_affected_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_updated_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_deleted_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_inserted_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  }
                ]
              },
              "data": [
                [
                  "876000",
                  "0",
                  "0",
                  "876000"
                ]
              ]
            },
            "text/plain": "<Spark SQL result set with 1 rows and 4 fields>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": [
                  {
                    "name": "num_affected_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_updated_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_deleted_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_inserted_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  }
                ]
              },
              "data": [
                [
                  "878400",
                  "0",
                  "0",
                  "878400"
                ]
              ]
            },
            "text/plain": "<Spark SQL result set with 1 rows and 4 fields>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": [
                  {
                    "name": "num_affected_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_updated_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_deleted_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_inserted_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  }
                ]
              },
              "data": [
                [
                  "876000",
                  "0",
                  "0",
                  "876000"
                ]
              ]
            },
            "text/plain": "<Spark SQL result set with 1 rows and 4 fields>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": [
                  {
                    "name": "num_affected_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_updated_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_deleted_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_inserted_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  }
                ]
              },
              "data": [
                [
                  "876000",
                  "0",
                  "0",
                  "876000"
                ]
              ]
            },
            "text/plain": "<Spark SQL result set with 1 rows and 4 fields>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": [
                  {
                    "name": "num_affected_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_updated_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_deleted_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  },
                  {
                    "name": "num_inserted_rows",
                    "type": "long",
                    "nullable": true,
                    "metadata": {}
                  }
                ]
              },
              "data": [
                [
                  "583200",
                  "0",
                  "0",
                  "583200"
                ]
              ]
            },
            "text/plain": "<Spark SQL result set with 1 rows and 4 fields>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we can see all the merges completed pretty quick and the data was merged into the delta table. We can query the data now to see the rows. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "SELECT COUNT(*) FROM temperatures_ext_delta"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "venkyspark1001",
              "session_id": "1",
              "statement_id": 18,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-10-08T19:45:13.086414Z",
              "session_start_time": null,
              "execution_start_time": "2023-10-08T19:45:13.2731495Z",
              "execution_finish_time": "2023-10-08T19:45:15.1590036Z",
              "spark_jobs": null,
              "parent_msg_id": "8c8a5757-dacc-4ea3-a7ca-25dd08e18755"
            },
            "text/plain": "StatementMeta(venkyspark1001, 1, 18, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "application/vnd.synapse.sparksql-result+json": {
              "schema": {
                "type": "struct",
                "fields": [
                  {
                    "name": "count(1)",
                    "type": "long",
                    "nullable": false,
                    "metadata": {
                      "__autoGeneratedAlias": "true"
                    }
                  }
                ]
              },
              "data": [
                [
                  "4965600"
                ]
              ]
            },
            "text/plain": "<Spark SQL result set with 1 rows and 1 fields>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": "This will merge to an external data table.",
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}